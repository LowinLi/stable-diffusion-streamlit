import streamlit as st
import numpy as np
import time
import threading
from datetime import datetime
import json
import os
from diffusers.training_utils import set_seed

from pages.model.inference import result_dir, quant_pipe
from pages.model.thread import PipelineThread

st.set_page_config(
    page_title="æ–‡å­—è½¬å›¾ç‰‡",
    page_icon="ðŸ§Š",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={},
)


st.title("æ‰©æ•£æ¨¡åž‹æ–‡å­—ç”Ÿæˆå›¾ç‰‡")
with st.form(key="my_form"):
    ce, c1, ce, c2, c3 = st.columns([0.07, 1, 0.07, 5, 0.07])
    with c1:
        st.subheader("å‚æ•°é…ç½®", anchor=None)
        num_inference_steps = st.slider(
            "ç”Ÿæˆè½®æ•°(num_inference_steps)",
            min_value=5,
            max_value=100,
            value=50,
            step=1,
            label_visibility="visible",
            help="çº¦å¤§ç”Ÿæˆå›¾ç‰‡è´¨é‡è¶Šé«˜ï¼Œä½†æ˜¯é€Ÿåº¦è¶Šæ…¢ \n The number of denoising steps. More denoising steps usually lead to a higher quality image at the expense of slower inference.",
        )
        guidance_scale = st.slider(
            "æŒ‡å¯¼å‚æ•°(guidance_scale)",
            min_value=0.0,
            max_value=30.0,
            value=7.0,
            step=0.1,
            help="å€¼è¶Šå¤§ï¼Œçº¦æŽ¥è¿‘è¾“å…¥æ–‡å­— \n Defined in https://arxiv.org/abs/2207.12598 \n Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`, usually at the expense of lower image quality.",
            label_visibility="visible",
        )
        height = st.slider(
            "é«˜åº¦åƒç´ (height)",
            min_value=64,
            max_value=1024,
            value=512,
            step=8,
            label_visibility="visible",
        )
        width = st.slider(
            "å®½åº¦åƒç´ (width)",
            min_value=64,
            max_value=1024,
            value=512,
            step=8,
            label_visibility="visible",
        )
        eta = st.slider(
            "eta (Î·)",
            min_value=0.0,
            max_value=5.0,
            value=0.0,
            step=0.1,
            help="Corresponds to parameter eta (Î·) in the DDIM paper: https://arxiv.org/abs/2010.02502",
            label_visibility="visible",
        )
        seed = st.slider(
            "ç§å­(seed)",
            min_value=0,
            max_value=1024,
            value=10,
            step=1,
            label_visibility="visible",
            help="é…ç½®ä¸åŒç§å­å¯ä»¥ç”Ÿæˆä¸åŒçš„å›¾ç‰‡",
        )

    with c2:
        text_prompt = st.text_area(
            "è¾“å…¥æç¤ºæ–‡å­—",
            value="",
            help="The prompt or prompts to guide the image generation",
            disabled=False,
            label_visibility="visible",
        )
        negative_prompt = st.text_area(
            "è¾“å…¥ä¸è¦ç”Ÿæˆçš„æ–‡å­—æè¿°ï¼Œä¸å¡«ä¸ºä¸ä½¿ç”¨",
            value="",
            help="The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored if `guidance_scale` is less than `1`).",
            disabled=False,
            label_visibility="visible",
        )
        negative_prompt = None
        submit_button = st.form_submit_button("å¼€å§‹ç”Ÿæˆ", help=None, args=None, kwargs=None)
        my_bar = st.progress(0)
        if not submit_button:
            st.stop()
        set_seed(seed)
        uid = datetime.now().strftime("%Y%m%d_%H:%M:%S")
        args = (
            text_prompt,
            height,
            width,
            num_inference_steps,
            guidance_scale,
            negative_prompt,
            eta
        )
        t = PipelineThread(func=quant_pipe, args=args)
        t.start()
        while True:
            time.sleep(1)
            if isinstance(t.func.scheduler.counter, int):
                counter = t.func.scheduler.counter
            else:
                counter = 0
            progress = min(
                t.func.scheduler.counter / (num_inference_steps + 1),
                1.0,
            )
            my_bar.progress(progress)
            if progress >= 1:
                break
        t.join()

        image_filename = os.path.join(result_dir, "text2image", uid, "image.png")
        json_filename = os.path.join(result_dir, "text2image", uid, "config.json")
        os.makedirs(os.path.join(result_dir, "text2image", uid), exist_ok=True)
        t.get_result().images[0].save(image_filename)
        with open(json_filename, "w") as f:
            config = {
                "text_prompt": text_prompt,
                "height": height,
                "width": width,
                "num_inference_steps": num_inference_steps,
                "guidance_scale": guidance_scale,
                "eta": eta,
                "seed": seed,
            }
            json.dump(config, f, indent=4, ensure_ascii=False)
        st.balloons()
        st.image(
            image_filename, channels="RGB", output_format="auto", caption=text_prompt
        )
        with open(json_filename, "r") as f:
            st.json(json.load(f), expanded=True)
